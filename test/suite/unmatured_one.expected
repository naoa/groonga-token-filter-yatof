register token_filters/yatof
[[0,0.0,0.0],true]
tokenize TokenBigram   "*今日は123雨だ *A!"   --normalizer NormalizerAuto   --token_filters TokenFilterUnmaturedOne
[
  [
    0,
    0.0,
    0.0
  ],
  [
    {
      "value": "*",
      "position": 0
    },
    {
      "value": "今日",
      "position": 1
    },
    {
      "value": "日は",
      "position": 2
    },
    {
      "value": "123",
      "position": 3
    },
    {
      "value": "雨だ",
      "position": 4
    },
    {
      "value": "*",
      "position": 5
    },
    {
      "value": "a",
      "position": 6
    },
    {
      "value": "!",
      "position": 7
    }
  ]
]
