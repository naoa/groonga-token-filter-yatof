register token_filters/yatof
[[0,0.0,0.0],true]
table_create tf_limits TABLE_HASH_KEY ShortText
[[0,0.0,0.0],true]
column_create tf_limits tf_limit COLUMN_SCALAR UInt32
[[0,0.0,0.0],true]
load --table tf_limits
[
{"_key": "a", "tf_limit": 3}
]
[[0,0.0,0.0],1]
tokenize TokenBigram "a a a a b b b b"--normalizer NormalizerAuto --token_filters TokenFilterTFLimit
[
  [
    0,
    0.0,
    0.0
  ],
  [
    {
      "value": "a",
      "position": 0
    },
    {
      "value": "a",
      "position": 1
    },
    {
      "value": "a",
      "position": 2
    },
    {
      "value": "b",
      "position": 4
    },
    {
      "value": "b",
      "position": 5
    },
    {
      "value": "b",
      "position": 6
    },
    {
      "value": "b",
      "position": 7
    }
  ]
]
